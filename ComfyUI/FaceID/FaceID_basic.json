{
  "last_node_id": 38,
  "last_link_id": 86,
  "nodes": [
    {
      "id": 5,
      "type": "CLIPTextEncode",
      "pos": [
        710,
        777
      ],
      "size": {
        "0": 400,
        "1": 160
      },
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 6
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            3
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "blurry, malformed, distorted, naked"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 7,
      "type": "VAELoader",
      "pos": [
        1369,
        1050
      ],
      "size": {
        "0": 388.2800598144531,
        "1": 58.84000015258789
      },
      "flags": {},
      "order": 0,
      "mode": 0,
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            8
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAELoader"
      },
      "widgets_values": [
        "vae-ft-mse-840000-ema-pruned.safetensors"
      ]
    },
    {
      "id": 2,
      "type": "CheckpointLoaderSimple",
      "pos": [
        50,
        700
      ],
      "size": {
        "0": 434.4700927734375,
        "1": 108.23002624511719
      },
      "flags": {},
      "order": 1,
      "mode": 0,
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            15
          ],
          "slot_index": 0
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            5,
            6
          ],
          "slot_index": 1
        },
        {
          "name": "VAE",
          "type": "VAE",
          "links": [],
          "slot_index": 2
        }
      ],
      "properties": {
        "Node name for S&R": "CheckpointLoaderSimple"
      },
      "widgets_values": [
        "BASIC\\realisticVisionV51_v51VAE.safetensors"
      ]
    },
    {
      "id": 32,
      "type": "CLIPVisionLoader",
      "pos": [
        732,
        74
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 2,
      "mode": 0,
      "outputs": [
        {
          "name": "CLIP_VISION",
          "type": "CLIP_VISION",
          "links": [
            80
          ],
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPVisionLoader"
      },
      "widgets_values": [
        "SD1.5\\pytorch_model.bin"
      ]
    },
    {
      "id": 11,
      "type": "IPAdapterApply",
      "pos": [
        1178,
        -22
      ],
      "size": {
        "0": 210,
        "1": 278
      },
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "ipadapter",
          "type": "IPADAPTER",
          "link": 10
        },
        {
          "name": "clip_vision",
          "type": "CLIP_VISION",
          "link": 80,
          "slot_index": 1
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 77
        },
        {
          "name": "model",
          "type": "MODEL",
          "link": 16
        },
        {
          "name": "attn_mask",
          "type": "MASK",
          "link": null
        },
        {
          "name": "insightface",
          "type": "INSIGHTFACE",
          "link": 79,
          "slot_index": 5
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            82
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterApply"
      },
      "widgets_values": [
        0.9,
        0,
        "original",
        0,
        1,
        false
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 31,
      "type": "InsightFaceLoader",
      "pos": [
        730,
        378
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 3,
      "mode": 0,
      "outputs": [
        {
          "name": "INSIGHTFACE",
          "type": "INSIGHTFACE",
          "links": [
            79
          ],
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "InsightFaceLoader"
      },
      "widgets_values": [
        "CUDA"
      ]
    },
    {
      "id": 22,
      "type": "PreviewImage",
      "pos": [
        1956,
        568
      ],
      "size": {
        "0": 527.009765625,
        "1": 548.077880859375
      },
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 72
        }
      ],
      "properties": {
        "Node name for S&R": "PreviewImage"
      }
    },
    {
      "id": 37,
      "type": "FaceRestoreModelLoader",
      "pos": [
        1774,
        225
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 4,
      "mode": 0,
      "outputs": [
        {
          "name": "FACERESTORE_MODEL",
          "type": "FACERESTORE_MODEL",
          "links": [
            83
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "FaceRestoreModelLoader"
      },
      "widgets_values": [
        "GFPGANv1.4.pth"
      ]
    },
    {
      "id": 38,
      "type": "PreviewImage",
      "pos": [
        2510,
        569
      ],
      "size": {
        "0": 527.009765625,
        "1": 548.077880859375
      },
      "flags": {},
      "order": 16,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 85
        }
      ],
      "properties": {
        "Node name for S&R": "PreviewImage"
      }
    },
    {
      "id": 9,
      "type": "IPAdapterModelLoader",
      "pos": [
        739,
        -92
      ],
      "size": {
        "0": 300,
        "1": 60
      },
      "flags": {},
      "order": 5,
      "mode": 0,
      "outputs": [
        {
          "name": "IPADAPTER",
          "type": "IPADAPTER",
          "links": [
            10
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterModelLoader"
      },
      "widgets_values": [
        "ip-adapter-faceid-plusv2_sd15.bin"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 14,
      "type": "LoraLoaderModelOnly",
      "pos": [
        680,
        196
      ],
      "size": {
        "0": 386.830078125,
        "1": 107.74998474121094
      },
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 15
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            16
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "LoraLoaderModelOnly"
      },
      "widgets_values": [
        "FaceID\\ip-adapter-faceid-plusv2_sd15_lora.safetensors",
        0.6
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 36,
      "type": "FaceRestoreWithModel",
      "pos": [
        2156,
        275
      ],
      "size": {
        "0": 315,
        "1": 78
      },
      "flags": {},
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "facerestore_model",
          "type": "FACERESTORE_MODEL",
          "link": 83
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 86
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            85
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "FaceRestoreWithModel"
      },
      "widgets_values": [
        "YOLOv5n"
      ]
    },
    {
      "id": 3,
      "type": "EmptyLatentImage",
      "pos": [
        892,
        994
      ],
      "size": {
        "0": 210,
        "1": 110
      },
      "flags": {},
      "order": 6,
      "mode": 0,
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            4
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        512,
        512,
        1
      ]
    },
    {
      "id": 10,
      "type": "LoadImage",
      "pos": [
        180,
        -50
      ],
      "size": {
        "0": 390.733154296875,
        "1": 482.0174560546875
      },
      "flags": {},
      "order": 7,
      "mode": 0,
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            77
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null,
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "tmp_09ab4r9.png",
        "image"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 6,
      "type": "VAEDecode",
      "pos": [
        1904,
        390
      ],
      "size": {
        "0": 140,
        "1": 50
      },
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 7
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 8
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            72,
            86
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      }
    },
    {
      "id": 1,
      "type": "KSampler",
      "pos": [
        1410,
        405
      ],
      "size": [
        240,
        474
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 82
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 2
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 3
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 4
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            7
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        1067220995109163,
        "randomize",
        30,
        6,
        "dpmpp_2m",
        "karras",
        1
      ]
    },
    {
      "id": 4,
      "type": "CLIPTextEncode",
      "pos": [
        710,
        570
      ],
      "size": {
        "0": 400,
        "1": 160
      },
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 5
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            2
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "closeup photo of a woman wearing a white spring dress in a garden,\n\nhigh quality, diffuse light, highly detailed, 4k"
      ],
      "color": "#232",
      "bgcolor": "#353"
    }
  ],
  "links": [
    [
      2,
      4,
      0,
      1,
      1,
      "CONDITIONING"
    ],
    [
      3,
      5,
      0,
      1,
      2,
      "CONDITIONING"
    ],
    [
      4,
      3,
      0,
      1,
      3,
      "LATENT"
    ],
    [
      5,
      2,
      1,
      4,
      0,
      "CLIP"
    ],
    [
      6,
      2,
      1,
      5,
      0,
      "CLIP"
    ],
    [
      7,
      1,
      0,
      6,
      0,
      "LATENT"
    ],
    [
      8,
      7,
      0,
      6,
      1,
      "VAE"
    ],
    [
      10,
      9,
      0,
      11,
      0,
      "IPADAPTER"
    ],
    [
      15,
      2,
      0,
      14,
      0,
      "MODEL"
    ],
    [
      16,
      14,
      0,
      11,
      3,
      "MODEL"
    ],
    [
      72,
      6,
      0,
      22,
      0,
      "IMAGE"
    ],
    [
      77,
      10,
      0,
      11,
      2,
      "IMAGE"
    ],
    [
      79,
      31,
      0,
      11,
      5,
      "INSIGHTFACE"
    ],
    [
      80,
      32,
      0,
      11,
      1,
      "CLIP_VISION"
    ],
    [
      82,
      11,
      0,
      1,
      0,
      "MODEL"
    ],
    [
      83,
      37,
      0,
      36,
      0,
      "FACERESTORE_MODEL"
    ],
    [
      85,
      36,
      0,
      38,
      0,
      "IMAGE"
    ],
    [
      86,
      6,
      0,
      36,
      1,
      "IMAGE"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {},
  "version": 0.4
}